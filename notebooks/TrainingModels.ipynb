{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING LSTM ASR MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Class\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "from model_trainer import ModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTrainer:INFO->Successfully Created Model Trainer Class Object Instance\n"
     ]
    }
   ],
   "source": [
    "# Creating Model Trainer Class\n",
    "model_trainer = ModelTrainer(feature_used='logmelfb', duration_range=(2, 6), epoch=462)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTrainer:INFO->Successfully Loaded Audio Files\n"
     ]
    }
   ],
   "source": [
    "# Loading Audio Files to the Class\n",
    "model_trainer.load_audio_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTrainer:INFO->Successfully Extracted logmelfb features from Audio Files\n",
      "ModelTrainer:INFO->Successfully Constructed Model Inputs\n",
      "ModelTrainer:INFO->Successfully Load Labels and Alphabets\n",
      "ModelTrainer:INFO->Successfully Extracted Transcriptions\n",
      "ModelTrainer:INFO->Successfully Constructed Model Targets\n"
     ]
    }
   ],
   "source": [
    "# Extracting Features and Constructing Model Input and Target Values\n",
    "model_trainer.construct_inputs()\n",
    "model_trainer.construct_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTrainer:INFO->Successfully Split Train and Validation Sets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPES: \n",
      "\t TRAIN:  (4065, 591, 26) \n",
      "\tVALIDATION:  (1017, 591, 26)\n",
      "INPUT SEQUENCE LENGTH SHAPES: \n",
      "\t TRAIN:  (4065,) \n",
      "\tVALIDATION:  (1017,)\n",
      "TARGET SHAPES: \n",
      "\t TRAIN:  (4065, 70) \n",
      "\tVALIDATION:  (1017, 70)\n",
      "TARGET SEQUENCE LENGTH SHAPES: \n",
      "\t TRAIN:  (4065,) \n",
      "\tVALIDATION:  (1017,)\n"
     ]
    }
   ],
   "source": [
    "# Spliting Training and Validation Sets\n",
    "model_trainer.split_train_validation_sets()\n",
    "model_trainer.get_input_target_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STACKED LSTM LAYER MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ModelTrainer:INFO->Successfully Defined Model Input Parameters\n",
      "ModelTrainer:INFO->Successfully Defined STACKED LSTM MODEL\n",
      "ModelTrainer:INFO->Successfully Created Train and Predict Models\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_feature (InputLayer)      [(None, None, 26)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 26)     0           input_feature[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, None, 222)    221112      masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, None, 222)    888         lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, None, 222)    395160      batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, None, 222)    888         lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, None, 222)    395160      batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, None, 222)    888         lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, None, 222)    395160      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, None, 222)    888         lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, None, 70)     82040       batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_label (InputLayer)        [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 223)    15833       lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_label_len (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_feature_len (InputLayer)  [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc_loss_layer (CTCLossLayer)   (None, None, 223)    0           input_label[0][0]                \n",
      "                                                                 time_distributed[0][0]           \n",
      "                                                                 input_label_len[0][0]            \n",
      "                                                                 input_feature_len[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 1,508,017\n",
      "Trainable params: 1,506,241\n",
      "Non-trainable params: 1,776\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Defining Input parameters for model and selecting model to use\n",
    "model_trainer.define_model_input_params()\n",
    "model_trainer.create_train_predict_models(model_name='stacked_lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: 'STACKED LSTM Layers' does not exist. Creating a new experiment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/08/15 19:00:20 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '02b14b5810b04fb3a9d899cca475f93d', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current tensorflow workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/462\n",
      "59/59 [==============================] - 3924s 67s/step - loss: 574.2317 - ler: 1.0001 - val_loss: 150.0602 - val_ler: 0.9996\n",
      "\n",
      "Epoch 00001: val_ler improved from inf to 0.99957, saving model to ../models\\stacked-lstm_train.h5\n",
      "Epoch 2/462\n",
      "59/59 [==============================] - 3601s 61s/step - loss: 152.3694 - ler: 0.9684 - val_loss: 139.6165 - val_ler: 0.9977\n",
      "\n",
      "Epoch 00002: val_ler improved from 0.99957 to 0.99773, saving model to ../models\\stacked-lstm_train.h5\n",
      "Epoch 3/462\n",
      "59/59 [==============================] - 4049s 69s/step - loss: 141.1560 - ler: 0.9970 - val_loss: 136.9290 - val_ler: 0.9989\n",
      "\n",
      "Epoch 00003: val_ler did not improve from 0.99773\n",
      "Epoch 4/462\n",
      " 1/59 [..............................] - ETA: 1:06:04 - loss: 142.8207 - ler: 1.0000"
     ]
    }
   ],
   "source": [
    "# Training Selected Model\n",
    "model_trainer.train_model(model_name='stacked-lstm', mlflow_experiment='STACKED LSTM Layers',\n",
    "                          batch_size=70, optimizer='adam', learning_rate=0.001, early_stop=False) #0.001(best so far)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Trained Model Loss Diagrams\n",
    "# Loss Diagram (Type 1)\n",
    "model_trainer.draw_result_plots('stacked_lstm',1)\n",
    "# LER Diagram (Type 2)\n",
    "model_trainer.draw_result_plots('stacked_lstm',2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe Validation Set\n",
    "model_trainer.transcript_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Sample Transcriptions Made by the Model\n",
    "model_trainer.get_sample_trained_model_transcriptions(amount=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Input parameters for model and selecting model to use\n",
    "model_trainer.define_model_input_params()\n",
    "model_trainer.create_train_predict_models(model_name='bidirectional_lstm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Selected Model\n",
    "model_trainer.train_model(model_name='stacked-lstm', mlflow_experiment='BIDIRECTIONAL LSTM Layers',\n",
    "                          batch_size=50, optimizer='sgd', learning_rate=0.0005, early_stop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Trained Model Loss Diagrams\n",
    "# Loss Diagram (Type 1)\n",
    "model_trainer.draw_result_plots('bidirectional_lstm', 1)\n",
    "# LER Diagram (Type 2)\n",
    "model_trainer.draw_result_plots('bidirectional_lstm', 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Sample Transcriptions Made by the Model\n",
    "model_trainer.get_sample_trained_model_transcriptions()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
